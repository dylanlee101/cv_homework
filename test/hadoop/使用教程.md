使用Hadoop版本为2.7.7

将hadoop.tar.gz放入虚拟机后，即可使用`tar -zxvf hadoop.tar.gz`解压，解压出来软件名为`hadoop-2.7`。

进入hadoop目录：

```
cd hadoop-2.7/
```

此处需要先新建文件：

```
mkdir -p /data/hadoop/app/tmp/dfs/name
mkdir -p /data/hadoop/app/tmp/dfs/data
```

执行 NameNode 的格式化:

```
./bin/hdfs namenode -format
```

接着开启 NameNode 和 DataNode 守护进程，输入Yes:

```
./sbin/start-dfs.sh 
```

使用后jps，若有以下进程则为启动成功：

```
22881 SecondaryNameNode
22424 NameNode
22633 DataNode
23705 Jps
```

下面开始运行实例：

新建文件夹并复制数据：

```
./bin/hdfs dfs -mkdir /input
./bin/hdfs dfs -put ./etc/hadoop/*.xml /input
```

复制完成后，可以通过如下命令查看文件列表：

```
./bin/hdfs dfs -ls /input
```

运行 MapReduce 作业：

```
./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep /input /output 'dfs[a-z.]+'
```

查看运行结果的命令：

```
./bin/hdfs dfs -cat /output/*
```

